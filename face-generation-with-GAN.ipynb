{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "import glob \n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.math import reduce_mean\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.nn import sigmoid_cross_entropy_with_logits as loss\n",
    "from tensorflow.keras.layers import Dense,Conv2DTranspose,Conv2D\n",
    "from tensorflow.nn import batch_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "import_ids = glob.glob(\"../input/celeba-dataset/img_align_celeba/img_align_celeba/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "crop = (30,55,150,175)\n",
    "import_ids= import_ids[:4000]\n",
    "images=[np.array((Image.open(i).crop(crop)).resize((64,64))) for i in import_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "for i in range(len(images)):\n",
    "    images[i] = ((images[i] - images[i].min())/(255 - images[i].min()))\n",
    "    images[i] = images[i]*2-1\n",
    "    \n",
    "images = np.array(images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "def generator(noise,reuse=False,alpha=0.2,training=True):\n",
    "    with tf.variable_scope('generator',reuse=reuse):\n",
    "        x = Dense(noise,4*4*512)\n",
    "        x = tf.reshape(x,(-1,4,4,512))\n",
    "        x = batch_normalization(x,training=training)\n",
    "        x = tf.maximum(0,x)\n",
    "        \n",
    "        x = Conv2DTranspose(x,256,5,2,padding='same')\n",
    "        x = batch_normalization(x,training=training)\n",
    "        x = tf.maximum(0,x)\n",
    "        \n",
    "        x = Conv2DTranspose(x,128,5,2,padding='same')\n",
    "        x = batch_normalization(x,training=training)\n",
    "        x = tf.maximum(0,x)\n",
    "        \n",
    "        x = Conv2DTranspose(x,64,5,2,padding='same')\n",
    "        x = batch_normalization(x,training=training)\n",
    "        x = tf.maximum(0,x)\n",
    "        \n",
    "        logits= Conv2DTranspose(x,3,5,2,padding='same')\n",
    "        out = tf.tanh(logits)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "def discriminator(x, reuse=False, alpha=0.2, training=True):\n",
    "    \n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        \n",
    "        x = Conv2D(x, 32, 5, 2, padding='same')\n",
    "        x = tf.maximum(alpha*x, x)\n",
    "        \n",
    "        x = Conv2D(x, 64, 5, 2, padding='same')\n",
    "        x = batch_normalization(x, training=training)\n",
    "        x = tf.maximum(alpha*x, x)\n",
    "        \n",
    "        x = Conv2D(x, 128, 5, 2, padding='same')\n",
    "        x = batch_normalization(x, training=training)\n",
    "        x = tf.maximum(alpha*x, x)\n",
    "        \n",
    "        x = Conv2D(x, 256, 5, 2, padding='same')\n",
    "        x = batch_normalization(x, training=training)\n",
    "        x = tf.maximum(alpha*x, x)        \n",
    "        \n",
    "        flatten = tf.reshape(x, (-1, 4*4*256))\n",
    "        logits = dense(flatten, 1)\n",
    "        out = tf.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Creating GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\n",
    "# from tensorflow.keras.layers.merge import _Merge\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class GAN():\n",
    "    def __init__(self\n",
    "        , input_dim\n",
    "        , discriminator_conv_filters\n",
    "        , discriminator_conv_kernel_size\n",
    "        , discriminator_conv_strides\n",
    "        , discriminator_batch_norm_momentum\n",
    "        , discriminator_activation\n",
    "        , discriminator_dropout_rate\n",
    "        , discriminator_learning_rate\n",
    "        , generator_initial_dense_layer_size\n",
    "        , generator_upsample\n",
    "        , generator_conv_filters\n",
    "        , generator_conv_kernel_size\n",
    "        , generator_conv_strides\n",
    "        , generator_batch_norm_momentum\n",
    "        , generator_activation\n",
    "        , generator_dropout_rate\n",
    "        , generator_learning_rate\n",
    "        , optimiser\n",
    "        , z_dim\n",
    "        ):\n",
    "\n",
    "        self.name = 'gan'\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.discriminator_conv_filters = discriminator_conv_filters\n",
    "        self.discriminator_conv_kernel_size = discriminator_conv_kernel_size\n",
    "        self.discriminator_conv_strides = discriminator_conv_strides\n",
    "        self.discriminator_batch_norm_momentum = discriminator_batch_norm_momentum\n",
    "        self.discriminator_activation = discriminator_activation\n",
    "        self.discriminator_dropout_rate = discriminator_dropout_rate\n",
    "        self.discriminator_learning_rate = discriminator_learning_rate\n",
    "\n",
    "        self.generator_initial_dense_layer_size = generator_initial_dense_layer_size\n",
    "        self.generator_upsample = generator_upsample\n",
    "        self.generator_conv_filters = generator_conv_filters\n",
    "        self.generator_conv_kernel_size = generator_conv_kernel_size\n",
    "        self.generator_conv_strides = generator_conv_strides\n",
    "        self.generator_batch_norm_momentum = generator_batch_norm_momentum\n",
    "        self.generator_activation = generator_activation\n",
    "        self.generator_dropout_rate = generator_dropout_rate\n",
    "        self.generator_learning_rate = generator_learning_rate\n",
    "        \n",
    "        self.optimiser = optimiser\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.n_layers_discriminator = len(discriminator_conv_filters)\n",
    "        self.n_layers_generator = len(generator_conv_filters)\n",
    "\n",
    "        self.weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "        self.d_losses = []\n",
    "        self.g_losses = []\n",
    "\n",
    "        self.epoch = 0\n",
    "\n",
    "        self._build_discriminator()\n",
    "        self._build_generator()\n",
    "\n",
    "        self._build_adversarial()\n",
    "\n",
    "    def get_activation(self, activation):\n",
    "        if activation == 'leaky_relu':\n",
    "            layer = LeakyReLU(alpha = 0.2)\n",
    "        else:\n",
    "            layer = Activation(activation)\n",
    "        return layer\n",
    "\n",
    "    def _build_discriminator(self):\n",
    "\n",
    "        ### THE discriminator\n",
    "        discriminator_input = Input(shape=self.input_dim, name='discriminator_input')\n",
    "\n",
    "        x = discriminator_input\n",
    "\n",
    "        for i in range(self.n_layers_discriminator):\n",
    "\n",
    "            x = Conv2D(\n",
    "                filters = self.discriminator_conv_filters[i]\n",
    "                , kernel_size = self.discriminator_conv_kernel_size[i]\n",
    "                , strides = self.discriminator_conv_strides[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'discriminator_conv_' + str(i)\n",
    "                , kernel_initializer = self.weight_init\n",
    "                )(x)\n",
    "\n",
    "            if self.discriminator_batch_norm_momentum and i > 0:\n",
    "                x = BatchNormalization(momentum = self.discriminator_batch_norm_momentum)(x)\n",
    "\n",
    "            x = self.get_activation(self.discriminator_activation)(x)\n",
    "\n",
    "            if self.discriminator_dropout_rate:\n",
    "                x = Dropout(rate = self.discriminator_dropout_rate)(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        discriminator_output = Dense(1, activation='sigmoid', kernel_initializer = self.weight_init)(x)\n",
    "\n",
    "        self.discriminator = Model(discriminator_input, discriminator_output)\n",
    "\n",
    "\n",
    "    def _build_generator(self):\n",
    "\n",
    "        ### THE generator\n",
    "\n",
    "        generator_input = Input(shape=(self.z_dim,), name='generator_input')\n",
    "\n",
    "        x = generator_input\n",
    "\n",
    "        x = Dense(np.prod(self.generator_initial_dense_layer_size), kernel_initializer = self.weight_init)(x)\n",
    "\n",
    "        if self.generator_batch_norm_momentum:\n",
    "            x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)\n",
    "\n",
    "        x = self.get_activation(self.generator_activation)(x)\n",
    "\n",
    "        x = Reshape(self.generator_initial_dense_layer_size)(x)\n",
    "\n",
    "        if self.generator_dropout_rate:\n",
    "            x = Dropout(rate = self.generator_dropout_rate)(x)\n",
    "\n",
    "        for i in range(self.n_layers_generator):\n",
    "\n",
    "            if self.generator_upsample[i] == 2:\n",
    "                x = UpSampling2D()(x)\n",
    "                x = Conv2D(\n",
    "                    filters = self.generator_conv_filters[i]\n",
    "                    , kernel_size = self.generator_conv_kernel_size[i]\n",
    "                    , padding = 'same'\n",
    "                    , name = 'generator_conv_' + str(i)\n",
    "                    , kernel_initializer = self.weight_init\n",
    "                )(x)\n",
    "            else:\n",
    "\n",
    "                x = Conv2DTranspose(\n",
    "                    filters = self.generator_conv_filters[i]\n",
    "                    , kernel_size = self.generator_conv_kernel_size[i]\n",
    "                    , padding = 'same'\n",
    "                    , strides = self.generator_conv_strides[i]\n",
    "                    , name = 'generator_conv_' + str(i)\n",
    "                    , kernel_initializer = self.weight_init\n",
    "                    )(x)\n",
    "\n",
    "            if i < self.n_layers_generator - 1:\n",
    "\n",
    "                if self.generator_batch_norm_momentum:\n",
    "                    x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)\n",
    "\n",
    "                x = self.get_activation(self.generator_activation)(x)\n",
    "                    \n",
    "                \n",
    "            else:\n",
    "\n",
    "                x = Activation('tanh')(x)\n",
    "\n",
    "\n",
    "        generator_output = x\n",
    "\n",
    "        self.generator = Model(generator_input, generator_output)\n",
    "\n",
    "       \n",
    "    def get_opti(self, lr):\n",
    "        if self.optimiser == 'adam':\n",
    "            opti = Adam(lr=lr, beta_1=0.5)\n",
    "        elif self.optimiser == 'rmsprop':\n",
    "            opti = RMSprop(lr=lr)\n",
    "        else:\n",
    "            opti = Adam(lr=lr)\n",
    "\n",
    "        return opti\n",
    "\n",
    "    def set_trainable(self, m, val):\n",
    "        m.trainable = val\n",
    "        for l in m.layers:\n",
    "            l.trainable = val\n",
    "\n",
    "\n",
    "    def _build_adversarial(self):\n",
    "        \n",
    "        ### COMPILE DISCRIMINATOR\n",
    "\n",
    "        self.discriminator.compile(\n",
    "        optimizer=self.get_opti(self.discriminator_learning_rate)  \n",
    "        , loss = 'binary_crossentropy'\n",
    "        ,  metrics = ['accuracy']\n",
    "        )\n",
    "        \n",
    "        ### COMPILE THE FULL GAN\n",
    "\n",
    "        self.set_trainable(self.discriminator, False)\n",
    "\n",
    "        model_input = Input(shape=(self.z_dim,), name='model_input')\n",
    "        model_output = self.discriminator(self.generator(model_input))\n",
    "        self.model = Model(model_input, model_output)\n",
    "\n",
    "        self.model.compile(optimizer=self.get_opti(self.generator_learning_rate) , loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        self.set_trainable(self.discriminator, True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def train_discriminator(self, x_train, batch_size, using_generator):\n",
    "\n",
    "        valid = np.ones((batch_size,1))\n",
    "        fake = np.zeros((batch_size,1))\n",
    "\n",
    "        if using_generator:\n",
    "            true_imgs = next(x_train)[0]\n",
    "            if true_imgs.shape[0] != batch_size:\n",
    "                true_imgs = next(x_train)[0]\n",
    "        else:\n",
    "            idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "            true_imgs = x_train[idx]\n",
    "        \n",
    "        noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        d_loss_real, d_acc_real =   self.discriminator.train_on_batch(true_imgs, valid)\n",
    "        d_loss_fake, d_acc_fake =   self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss =  0.5 * (d_loss_real + d_loss_fake)\n",
    "        d_acc = 0.5 * (d_acc_real + d_acc_fake)\n",
    "\n",
    "        return [d_loss, d_loss_real, d_loss_fake, d_acc, d_acc_real, d_acc_fake]\n",
    "\n",
    "    def train_generator(self, batch_size):\n",
    "        valid = np.ones((batch_size,1))\n",
    "        noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
    "        return self.model.train_on_batch(noise, valid)\n",
    "\n",
    "\n",
    "    def train(self, x_train, batch_size, epochs, run_folder\n",
    "    , print_every_n_batches = 50\n",
    "    , using_generator = False):\n",
    "\n",
    "        for epoch in range(self.epoch, self.epoch + epochs):\n",
    "\n",
    "            d = self.train_discriminator(x_train, batch_size, using_generator)\n",
    "            g = self.train_generator(batch_size)\n",
    "\n",
    "            print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f] [G acc: %.3f]\" % (epoch, d[0], d[1], d[2], d[3], d[4], d[5], g[0], g[1]))\n",
    "\n",
    "            self.d_losses.append(d)\n",
    "            self.g_losses.append(g)\n",
    "\n",
    "            if epoch % print_every_n_batches == 0:\n",
    "                self.sample_images(run_folder)\n",
    "                self.model.save_weights(os.path.join(run_folder, 'weights/weights-%d.h5' % (epoch)))\n",
    "                self.model.save_weights(os.path.join(run_folder, 'weights/weights.h5'))\n",
    "                self.save_model(run_folder)\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "    \n",
    "    def sample_images(self, run_folder):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.z_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        gen_imgs = 0.5 * (gen_imgs + 1)\n",
    "        gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "\n",
    "        fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "        cnt = 0\n",
    "\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]), cmap = 'gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(os.path.join(run_folder, \"images/sample_%d.png\" % self.epoch))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def plot_model(self, run_folder):\n",
    "        plot_model(self.model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes = True, show_layer_names = True)\n",
    "        plot_model(self.discriminator, to_file=os.path.join(run_folder ,'viz/discriminator.png'), show_shapes = True, show_layer_names = True)\n",
    "        plot_model(self.generator, to_file=os.path.join(run_folder ,'viz/generator.png'), show_shapes = True, show_layer_names = True)\n",
    "\n",
    "\n",
    "\n",
    "    def save(self, folder):\n",
    "\n",
    "        with open(os.path.join(folder, 'params.pkl'), 'wb') as f:\n",
    "            pkl.dump([\n",
    "                self.input_dim\n",
    "                , self.discriminator_conv_filters\n",
    "                , self.discriminator_conv_kernel_size\n",
    "                , self.discriminator_conv_strides\n",
    "                , self.discriminator_batch_norm_momentum\n",
    "                , self.discriminator_activation\n",
    "                , self.discriminator_dropout_rate\n",
    "                , self.discriminator_learning_rate\n",
    "                , self.generator_initial_dense_layer_size\n",
    "                , self.generator_upsample\n",
    "                , self.generator_conv_filters\n",
    "                , self.generator_conv_kernel_size\n",
    "                , self.generator_conv_strides\n",
    "                , self.generator_batch_norm_momentum\n",
    "                , self.generator_activation\n",
    "                , self.generator_dropout_rate\n",
    "                , self.generator_learning_rate\n",
    "                , self.optimiser\n",
    "                , self.z_dim\n",
    "                ], f)\n",
    "\n",
    "        self.plot_model(folder)\n",
    "\n",
    "    def save_model(self, run_folder):\n",
    "        self.model.save(os.path.join(run_folder, 'model.h5'))\n",
    "        self.discriminator.save(os.path.join(run_folder, 'discriminator.h5'))\n",
    "        self.generator.save(os.path.join(run_folder, 'generator.h5'))\n",
    "        pkl.dump(self, open( os.path.join(run_folder, \"obj.pkl\"), \"wb\" ))\n",
    "\n",
    "    def load_weights(self, filepath):\n",
    "        self.model.load_weights(filepath)\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "gan = GAN(input_dim = (28,28,1)\n",
    "            , discriminator_conv_filters = [64,64,128,128]\n",
    "            , discriminator_conv_kernel_size = [5,5,5,5]\n",
    "            , discriminator_conv_strides = [2,2,2,1]\n",
    "            , discriminator_batch_norm_momentum = None\n",
    "            , discriminator_activation = 'relu'\n",
    "            , discriminator_dropout_rate = 0.4\n",
    "            , discriminator_learning_rate = 0.0008\n",
    "            , generator_initial_dense_layer_size = (7, 7, 64)\n",
    "            , generator_upsample = [2,2, 1, 1]\n",
    "            , generator_conv_filters = [128,64, 64,1]\n",
    "            , generator_conv_kernel_size = [5,5,5,5]\n",
    "            , generator_conv_strides = [1,1, 1, 1]\n",
    "            , generator_batch_norm_momentum = 0.9\n",
    "            , generator_activation = 'relu'\n",
    "            , generator_dropout_rate = None\n",
    "            , generator_learning_rate = 0.0004\n",
    "            , optimiser = 'rmsprop'\n",
    "            , z_dim = 100\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "\n",
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "path_celeb = []\n",
    "train_path_celeb = \"../input/celeba-dataset/img_align_celeba/img_align_celeba/\"\n",
    "for path in os.listdir(train_path_celeb):\n",
    "    if '.jpg' in path:\n",
    "        path_celeb.append(os.path.join(train_path_celeb, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "len(path_celeb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "new_path=path_celeb[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "len(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "crop = (30, 55, 150, 175) #croping size for the image so that only the face at centre is obtained\n",
    "images = [np.array((Image.open(path).crop(crop)).resize((64,64))) for path in new_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "path_celeb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(path_celeb[0])\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "type(gray)\n",
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "gray2 = np.array(gray).resize((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "print(gray2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "images = Image.open(path_celeb[0]).convert(\"LA\")\n",
    "plt.imshow(images)\n",
    "print(images.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "crop = (30, 55, 150, 175)\n",
    "img=np.array((Image.open(path_celeb[0]).crop(crop)).resize((64,64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "img2=np.array((Image.open(path_celeb[1]).convert(\"LA\").crop(crop)).resize((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "img3 = np.array((Image.open(path_celeb[1]).convert(\"GRAY\")).resize((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "print(img3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "from skimage import io\n",
    "img = io.imread(path_celeb[1], as_gray=True)\n",
    "img.shape\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "img_nm = np.array(img)\n",
    "img_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "img_nm=img_nm.resize((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "print(img_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Another Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dropout,Dense,Flatten,Conv2DTranspose,BatchNormalization,LeakyReLU,Reshape\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "import os \n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "path_celeb = []\n",
    "train_path_celeb = \"../input/celeba-dataset/img_align_celeba/img_align_celeba/\"\n",
    "for path in os.listdir(train_path_celeb):\n",
    "    if '.jpg' in path:\n",
    "        path_celeb.append(os.path.join(train_path_celeb,path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "new_path=path_celeb[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "crop = (30, 55, 150, 175) #croping size for the image so that only the face at centre is obtained\n",
    "images = [np.array((Image.open(path).crop(crop)).resize((64,64))) for path in new_path]\n",
    "\n",
    "for i in range(len(images)):\n",
    "    images[i] = ((images[i] - images[i].min())/(255 - images[i].min()))\n",
    "    \n",
    "images = np.array(images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "train_data=images\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "fig,ax=plt.subplots(2,5)\n",
    "fig.suptitle(\"Real Images\")\n",
    "idx=800\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "            ax[i,j].imshow(train_data[idx].reshape(64,64,3))\n",
    "            #ax[i,j].set_title(\"Real Image\")\n",
    "            \n",
    "            idx+=600\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "X_train = train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Making Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "noise_shape = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "generator = Sequential()\n",
    "generator.add(Dense(4*4*512,input_shape=[noise_shape]))\n",
    "generator.add(Reshape([4,4,512]))\n",
    "generator.add(Conv2DTranspose(256,kernel_size=4,strides=2,padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Conv2DTranspose(128,kernel_size=4,strides=2,padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Conv2DTranspose(64,kernel_size=4,strides=2,padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Conv2DTranspose(3,kernel_size=4,strides=2,padding='same',activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Descriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(32,kernel_size=4,strides=2,padding='same',input_shape=[64,64,3]))\n",
    "discriminator.add(Conv2D(64,kernel_size=4,strides=2,padding='same'))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(BatchNormalization())\n",
    "discriminator.add(Conv2D(128,kernel_size=4,strides=2,padding='same'))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(BatchNormalization())\n",
    "discriminator.add(Conv2D(256,kernel_size=4,strides=2,padding='same'))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dropout(0.5))\n",
    "discriminator.add(Dense(1,activation='sigmoid'))\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "#DCGAN combining the model\n",
    "GAN = Sequential([generator,discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "discriminator.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "GAN.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "GAN.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "epochs = 300\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "D_loss=[]\n",
    "G_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "outputs": [
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Currently on Epoch {epoch+1}\")\n",
    "        for i in range(X_train.shape[0]//batch_size):\n",
    "            if(i)%100 == 0 :\n",
    "                print(f\"\\tCurrently on batch number {i} of {len(X_train)//batch_size}\")\n",
    "                \n",
    "                noise = np.random.uniform(-1,1,size=[batch_size,noise_shape])\n",
    "                gen_image = generator.predict_on_batch(noise)\n",
    "                train_dataset = X_train[i*batch_size:(i+1)*batch_size]\n",
    "                \n",
    "                train_label = np.ones(shape=(batch_size,1))\n",
    "                discriminator.trainable=True\n",
    "                d_loss1 = discriminator.train_on_batch(train_dataset,train_label)\n",
    "                train_label = np.zeros(shape=(batch_size,1))\n",
    "                d_loss2 = discriminator.train_on_batch(gen_image,train_label)\n",
    "                noise = np.random.uniform(-1,1,size=[batch_size,noise_shape])\n",
    "                train_label = np.ones(shape=(batch_size,1))\n",
    "                discriminator.trainable= False\n",
    "                g_loss = GAN.train_on_batch(noise,train_label)\n",
    "                D_loss.append(d_loss1+d_loss2)\n",
    "                G_loss.append(g_loss)\n",
    "                \n",
    "            if epoch % 5 == 0:\n",
    "                samples = 10\n",
    "                x_fake = generator.predict(np.random.normal(loc=0,scale=1,size=(samples,100)))\n",
    "                for k in range(samples):\n",
    "                    plt.subplot(2,5,k+1)\n",
    "                    plt.imshow(x_fake[k].reshape(64,64,3))\n",
    "                    plt.xticks([])\n",
    "                    plt.yticks([])\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            print('Epochs:%d, Loss: D_real = %.3f, D_fake = %.3f, G = %.3f'%(epoch+1,d_loss1,d_loss2,g_loss))\n",
    "            \n",
    "print(\"Training is Complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}